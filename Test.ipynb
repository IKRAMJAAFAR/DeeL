{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "943kBY9CTjDa"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'tensorflow.python'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[2], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MinMaxScaler\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LSTM, Dense, RepeatVector, TimeDistributed, ConvLSTM2D, Flatten\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msvm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OneClassSVM\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\__init__.py:40\u001b[0m\n\u001b[0;32m     37\u001b[0m _os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mENABLE_RUNTIME_UPTIME_TELEMETRY\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Do not remove this line; See https://github.com/tensorflow/tensorflow/issues/42596\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pywrap_tensorflow \u001b[38;5;28;01mas\u001b[39;00m _pywrap_tensorflow  \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m module_util \u001b[38;5;28;01mas\u001b[39;00m _module_util\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazy_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KerasLazyLoader \u001b[38;5;28;01mas\u001b[39;00m _KerasLazyLoader\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.python'"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, RepeatVector, TimeDistributed, ConvLSTM2D, Flatten\n",
        "from sklearn.svm import OneClassSVM\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "l5nuGyP4Tl6Q"
      },
      "outputs": [],
      "source": [
        "# Load filtered data\n",
        "# train_df = pd.read_csv('DeeL\\Filtered\\filtered_training_scaled.csv')\n",
        "# valid_df = pd.read_csv('DeeL\\Filtered\\filtered_validation_scaled.csv')\n",
        "# test_df = pd.read_csv('DeeL\\Filtered\\filtered_testing_scaled.csv')\n",
        "\n",
        "# Load unfiltered data\n",
        "train_df = pd.read_csv('DeeL\\unfiltered\\unfiltered_training_scaled.csv')\n",
        "valid_df = pd.read_csv('DeeL\\unfiltered\\unfiltered_validation_scaled.csv')\n",
        "test_df = pd.read_csv('DeeL\\unfiltered\\unfiltered_testing_scaled.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "TVLj6IH1Tp-3"
      },
      "outputs": [],
      "source": [
        "scaler = MinMaxScaler()\n",
        "train_scaled = scaler.fit_transform(train_df[['value']])\n",
        "valid_scaled = scaler.transform(valid_df[['value']])\n",
        "test_scaled = scaler.transform(test_df[['value']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "PDZHugf0Tsda"
      },
      "outputs": [],
      "source": [
        "sequence_length = 30\n",
        "\n",
        "def create_sequences(data, sequence_length):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - sequence_length):\n",
        "        X.append(data[i:i+sequence_length, 0])\n",
        "        y.append(data[i+sequence_length, 0])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "X_train, y_train = create_sequences(train_scaled, sequence_length)\n",
        "X_valid, y_valid = create_sequences(valid_scaled, sequence_length)\n",
        "X_test, y_test = create_sequences(test_scaled, sequence_length)\n",
        "\n",
        "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
        "X_valid = X_valid.reshape((X_valid.shape[0], X_valid.shape[1], 1))\n",
        "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WigGEjThT57J",
        "outputId": "6c679858-1475-49c2-8d50-6f8cfae84166"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LSTM MSE: 0.216435\n",
            "LSTM Normalized Anomaly Score: 7595.00%\n"
          ]
        }
      ],
      "source": [
        "# Model 1: LSTM\n",
        "model = Sequential()\n",
        "model.add(LSTM(50, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=10, batch_size=64, validation_data=(X_valid, y_valid), verbose=0)\n",
        "\n",
        "predictions = model.predict(X_test, verbose=0)\n",
        "errors = np.abs(predictions - y_test)\n",
        "mse_lstm = np.mean(errors)\n",
        "threshold = np.percentile(errors, 95)\n",
        "anomalies_lstm = errors > threshold\n",
        "normalized_lstm_score = (np.sum(anomalies_lstm) / len(errors)) * 100\n",
        "\n",
        "# Print Results for LSTM\n",
        "print(f\"LSTM MSE: {mse_lstm:.6f}\")\n",
        "print(f\"LSTM Normalized Anomaly Score: {normalized_lstm_score:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scy1nPE6T-lO",
        "outputId": "149778a5-d04b-45bd-fa39-5f7c67a58dbb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Autoencoder Anomalies: 76\n"
          ]
        }
      ],
      "source": [
        "# Model 2: Autoencoder\n",
        "model = Sequential()\n",
        "model.add(LSTM(64, activation='relu', input_shape=(X_train.shape[1], 1), return_sequences=False))\n",
        "model.add(RepeatVector(X_train.shape[1]))\n",
        "model.add(LSTM(64, activation='relu', return_sequences=True))\n",
        "model.add(TimeDistributed(Dense(1)))\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "history = model.fit(X_train, X_train, epochs=10, batch_size=64, validation_data=(X_valid, X_valid), verbose=0)\n",
        "\n",
        "reconstruction = model.predict(X_test, verbose=0)\n",
        "reconstruction_error = np.mean(np.abs(reconstruction - X_test), axis=1)\n",
        "threshold = np.percentile(reconstruction_error, 95)\n",
        "anomalies_autoencoder = reconstruction_error > threshold\n",
        "\n",
        "# Print Results for Autoencoder\n",
        "print(f\"Autoencoder Anomalies: {np.sum(anomalies_autoencoder)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EzF5iMKLUCUN",
        "outputId": "01aa4edc-4f80-42d5-9a36-0e8e30ebd6e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ConvLSTM Anomalies: 76\n"
          ]
        }
      ],
      "source": [
        "# Model 3: ConvLSTM\n",
        "X_train_reshaped = X_train.reshape((X_train.shape[0], sequence_length, 1, 1, 1))\n",
        "X_valid_reshaped = X_valid.reshape((X_valid.shape[0], sequence_length, 1, 1, 1))\n",
        "X_test_reshaped = X_test.reshape((X_test.shape[0], sequence_length, 1, 1, 1))\n",
        "\n",
        "model = Sequential()\n",
        "model.add(ConvLSTM2D(64, (3, 3), padding='same', input_shape=(sequence_length, 1, 1, 1), return_sequences=True))\n",
        "model.add(ConvLSTM2D(64, (3, 3), padding='same', return_sequences=False))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "model.fit(X_train_reshaped, X_train[:, -1], epochs=10, batch_size=64, validation_data=(X_valid_reshaped, X_valid[:, -1]), verbose=0)\n",
        "\n",
        "predictions = model.predict(X_test_reshaped, verbose=0)\n",
        "error = np.mean(np.abs(X_test_reshaped[:, :, 0, 0, 0] - predictions), axis=1)\n",
        "threshold = np.percentile(error, 95)\n",
        "anomalies_convlstm = error > threshold\n",
        "\n",
        "# Print Results for ConvLSTM\n",
        "print(f\"ConvLSTM Anomalies: {np.sum(anomalies_convlstm)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bOhEjrmUFTn",
        "outputId": "df73a9d4-0704-4c0d-a0a2-21d831d9cbad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "One-Class SVM Anomalies: 314\n"
          ]
        }
      ],
      "source": [
        "# Model 4: One-Class SVM\n",
        "X_train_flat = X_train.reshape((X_train.shape[0], -1))\n",
        "X_valid_flat = X_valid.reshape((X_valid.shape[0], -1))\n",
        "X_test_flat = X_test.reshape((X_test.shape[0], -1))\n",
        "\n",
        "svm = OneClassSVM(nu=0.05, kernel='rbf', gamma=0.1)\n",
        "svm.fit(X_train_flat)\n",
        "predictions = svm.predict(X_test_flat)\n",
        "anomalies_svm = predictions == -1\n",
        "\n",
        "# Print Results for One-Class SVM\n",
        "print(f\"One-Class SVM Anomalies: {np.sum(anomalies_svm)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7x6P_M3UHrR",
        "outputId": "c53a6d8e-7279-4cfa-b9a0-28e409a2b263"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Seasonal Decomposition Anomalies: 76\n"
          ]
        }
      ],
      "source": [
        "# Model 5: Seasonal Decomposition\n",
        "series = test_df['value']\n",
        "decomposition = seasonal_decompose(series, model='additive', period=sequence_length)\n",
        "residual = decomposition.resid.dropna()\n",
        "threshold = np.percentile(np.abs(residual), 95)\n",
        "anomalies_seasonal = np.abs(residual) > threshold\n",
        "\n",
        "# Print Results for Seasonal Decomposition\n",
        "print(f\"Seasonal Decomposition Anomalies: {np.sum(anomalies_seasonal)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCq7nr3HUKj9",
        "outputId": "8308df69-3cb3-4411-afa6-960e06340ca0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LSTM MSE: 0.216435\n",
            "LSTM Anomaly Score: 7594.9967083607635 anomalies (500.00%)\n",
            "Autoencoder Anomalies: 76 anomalies (5.00%)\n",
            "ConvLSTM Anomalies: 76 anomalies (5.00%)\n",
            "One-Class SVM Anomalies: 314 anomalies (20.67%)\n",
            "Seasonal Decomposition Anomalies: 76 anomalies (5.00%)\n"
          ]
        }
      ],
      "source": [
        "# Model Comparison\n",
        "results = {\n",
        "    'LSTM MSE': mse_lstm,\n",
        "    'LSTM Anomaly Score': normalized_lstm_score,\n",
        "    'Autoencoder Anomalies': np.sum(anomalies_autoencoder),\n",
        "    'ConvLSTM Anomalies': np.sum(anomalies_convlstm),\n",
        "    'One-Class SVM Anomalies': np.sum(anomalies_svm),\n",
        "    'Seasonal Decomposition Anomalies': np.sum(anomalies_seasonal)\n",
        "}\n",
        "\n",
        "for model, score in results.items():\n",
        "    if 'MSE' in model:\n",
        "        print(f'{model}: {score:.6f}')\n",
        "    else:\n",
        "        percentage = (score / len(errors)) * 100\n",
        "        print(f'{model}: {score} anomalies ({percentage:.2f}%)')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "cbRMJxNCWszL"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
        "import numpy as np\n",
        "\n",
        "# Helper function to calculate performance metrics\n",
        "def evaluate_anomaly_detection(true_anomalies, predicted_anomalies):\n",
        "    precision = precision_score(true_anomalies, predicted_anomalies)\n",
        "    recall = recall_score(true_anomalies, predicted_anomalies)\n",
        "    f1 = f1_score(true_anomalies, predicted_anomalies)\n",
        "    auc = roc_auc_score(true_anomalies, predicted_anomalies)\n",
        "    return precision, recall, f1, auc\n",
        "\n",
        "# Generate synthetic ground truth anomalies for testing purposes\n",
        "# This should be replaced with actual ground truth labels if available\n",
        "true_anomalies = (np.random.rand(len(errors)) < 0.1).astype(int)  # 10% anomalies as an example\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8Y4TWsPW3qM",
        "outputId": "f00574c9-ff29-40d9-c037-1ebca956b139"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LSTM Performance:\n",
            "Precision: 0.10, Recall: 0.05, F1-Score: 0.07, AUC: 0.50\n"
          ]
        }
      ],
      "source": [
        "# 1. LSTM Performance Test\n",
        "# ===============================\n",
        "# Ensure true_anomalies has the same length as predicted_anomalies_lstm\n",
        "true_anomalies = (np.random.rand(len(predicted_anomalies_lstm)) < 0.1).astype(int)  # Generate 10% anomalies\n",
        "\n",
        "# Ensure both arrays are binary and have the same shape\n",
        "true_anomalies = true_anomalies.ravel()  # Flatten ground truth to 1D\n",
        "predicted_anomalies_lstm = anomalies_lstm.astype(int).ravel()  # Convert predictions to binary and flatten\n",
        "\n",
        "# Evaluate anomaly detection performance\n",
        "precision_lstm, recall_lstm, f1_lstm, auc_lstm = evaluate_anomaly_detection(true_anomalies, predicted_anomalies_lstm)\n",
        "\n",
        "print(\"LSTM Performance:\")\n",
        "print(f\"Precision: {precision_lstm:.2f}, Recall: {recall_lstm:.2f}, F1-Score: {f1_lstm:.2f}, AUC: {auc_lstm:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-oCJBbTXX90",
        "outputId": "08665348-02da-4976-dc89-5d90cf9cf1ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Autoencoder Performance:\n",
            "Precision: 0.16, Recall: 0.07, F1-Score: 0.09, AUC: 0.51\n"
          ]
        }
      ],
      "source": [
        "# Model 2: Autoencoder Performance Test\n",
        "# ===============================\n",
        "# Ensure true_anomalies has the same length as predicted_anomalies_autoencoder\n",
        "true_anomalies = (np.random.rand(len(anomalies_autoencoder)) < 0.1).astype(int)  # Generate 10% anomalies\n",
        "\n",
        "# Ensure both arrays are binary and have the same shape\n",
        "true_anomalies = true_anomalies.ravel()\n",
        "predicted_anomalies_autoencoder = anomalies_autoencoder.astype(int).ravel()\n",
        "\n",
        "# Evaluate anomaly detection performance\n",
        "precision_autoencoder, recall_autoencoder, f1_autoencoder, auc_autoencoder = evaluate_anomaly_detection(\n",
        "    true_anomalies, predicted_anomalies_autoencoder\n",
        ")\n",
        "\n",
        "print(\"\\nAutoencoder Performance:\")\n",
        "print(f\"Precision: {precision_autoencoder:.2f}, Recall: {recall_autoencoder:.2f}, F1-Score: {f1_autoencoder:.2f}, AUC: {auc_autoencoder:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKBi-k9cXqcI",
        "outputId": "dcfba115-3d4c-42e7-b04c-f169f9924faa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ConvLSTM Performance:\n",
            "Precision: 0.11, Recall: 0.05, F1-Score: 0.07, AUC: 0.50\n"
          ]
        }
      ],
      "source": [
        "# Model 3: ConvLSTM Performance Test\n",
        "# ===============================\n",
        "# Ensure true_anomalies has the same length as predicted_anomalies_convlstm\n",
        "true_anomalies = (np.random.rand(len(anomalies_convlstm)) < 0.1).astype(int)  # Generate 10% anomalies\n",
        "\n",
        "# Ensure both arrays are binary and have the same shape\n",
        "true_anomalies = true_anomalies.ravel()\n",
        "predicted_anomalies_convlstm = anomalies_convlstm.astype(int).ravel()\n",
        "\n",
        "# Evaluate anomaly detection performance\n",
        "precision_convlstm, recall_convlstm, f1_convlstm, auc_convlstm = evaluate_anomaly_detection(\n",
        "    true_anomalies, predicted_anomalies_convlstm\n",
        ")\n",
        "\n",
        "print(\"\\nConvLSTM Performance:\")\n",
        "print(f\"Precision: {precision_convlstm:.2f}, Recall: {recall_convlstm:.2f}, F1-Score: {f1_convlstm:.2f}, AUC: {auc_convlstm:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JNjWZIqXtPT",
        "outputId": "fd2902cd-7138-4127-b99c-07bf521627a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "One-Class SVM Performance:\n",
            "Precision: 0.10, Recall: 0.21, F1-Score: 0.13, AUC: 0.50\n"
          ]
        }
      ],
      "source": [
        "# Model 4: One-Class SVM Performance Test\n",
        "# ===============================\n",
        "# Ensure true_anomalies has the same length as predicted_anomalies_svm\n",
        "true_anomalies = (np.random.rand(len(anomalies_svm)) < 0.1).astype(int)  # Generate 10% anomalies\n",
        "\n",
        "# Ensure both arrays are binary and have the same shape\n",
        "true_anomalies = true_anomalies.ravel()\n",
        "predicted_anomalies_svm = anomalies_svm.astype(int).ravel()\n",
        "\n",
        "# Evaluate anomaly detection performance\n",
        "precision_svm, recall_svm, f1_svm, auc_svm = evaluate_anomaly_detection(\n",
        "    true_anomalies, predicted_anomalies_svm\n",
        ")\n",
        "\n",
        "print(\"\\nOne-Class SVM Performance:\")\n",
        "print(f\"Precision: {precision_svm:.2f}, Recall: {recall_svm:.2f}, F1-Score: {f1_svm:.2f}, AUC: {auc_svm:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1U-YPvRgXviz",
        "outputId": "cd01ff74-f62a-4b46-e48d-8e3ec9b55eae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Seasonal Decomposition Performance:\n",
            "Precision: 0.07, Recall: 0.04, F1-Score: 0.05, AUC: 0.49\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-19-608b64d31df9>:8: FutureWarning: Series.ravel is deprecated. The underlying array is already 1D, so ravel is not necessary.  Use `to_numpy()` for conversion to a numpy array instead.\n",
            "  predicted_anomalies_seasonal = anomalies_seasonal.astype(int).ravel()\n"
          ]
        }
      ],
      "source": [
        "# Model 5: Seasonal Decomposition Performance Test\n",
        "# ===============================\n",
        "# Ensure true_anomalies has the same length as predicted_anomalies_seasonal\n",
        "true_anomalies = (np.random.rand(len(anomalies_seasonal)) < 0.1).astype(int)  # Generate 10% anomalies\n",
        "\n",
        "# Ensure both arrays are binary and have the same shape\n",
        "true_anomalies = true_anomalies.ravel()\n",
        "predicted_anomalies_seasonal = anomalies_seasonal.astype(int).ravel()\n",
        "\n",
        "# Evaluate anomaly detection performance\n",
        "precision_seasonal, recall_seasonal, f1_seasonal, auc_seasonal = evaluate_anomaly_detection(\n",
        "    true_anomalies, predicted_anomalies_seasonal\n",
        ")\n",
        "\n",
        "print(\"\\nSeasonal Decomposition Performance:\")\n",
        "print(f\"Precision: {precision_seasonal:.2f}, Recall: {recall_seasonal:.2f}, F1-Score: {f1_seasonal:.2f}, AUC: {auc_seasonal:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHB5BCppXx6f",
        "outputId": "7b050e00-05c2-43bf-be6c-635a38cd5dc2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Summary of Performance Results:\n",
            "                    Model  Precision    Recall  F1-Score       AUC\n",
            "0                    LSTM   0.099854  0.049866  0.066515  0.499926\n",
            "1             Autoencoder   0.157895  0.067416  0.094488  0.509845\n",
            "2                ConvLSTM   0.105263  0.054054  0.071429  0.502228\n",
            "3           One-Class SVM   0.095541  0.208333  0.131004  0.500894\n",
            "4  Seasonal Decomposition   0.065789  0.039683  0.049505  0.494357\n"
          ]
        }
      ],
      "source": [
        "# Summary of Results\n",
        "# ===============================\n",
        "results_summary = {\n",
        "    \"Model\": [\"LSTM\", \"Autoencoder\", \"ConvLSTM\", \"One-Class SVM\", \"Seasonal Decomposition\"],\n",
        "    \"Precision\": [precision_lstm, precision_autoencoder, precision_convlstm, precision_svm, precision_seasonal],\n",
        "    \"Recall\": [recall_lstm, recall_autoencoder, recall_convlstm, recall_svm, recall_seasonal],\n",
        "    \"F1-Score\": [f1_lstm, f1_autoencoder, f1_convlstm, f1_svm, f1_seasonal],\n",
        "    \"AUC\": [auc_lstm, auc_autoencoder, auc_convlstm, auc_svm, auc_seasonal]\n",
        "}\n",
        "\n",
        "results_df = pd.DataFrame(results_summary)\n",
        "print(\"\\nSummary of Performance Results:\")\n",
        "print(results_df)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
